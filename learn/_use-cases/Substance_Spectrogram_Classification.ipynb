{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substance Spectrogram Classification using QCi's Reservoir Computer\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We used QCi's EmuCore to build a method for classification of substances based on their spectrograms. The reader can refer to\n",
    "\n",
    "https://en.wikipedia.org/wiki/Spectroscopy\n",
    "\n",
    "to learn about spectroscopy of substances. The reader may also refer to an inetersting simulator \n",
    "\n",
    "https://phet.colorado.edu/sims/html/molecules-and-light/latest/molecules-and-light_en.html\n",
    "\n",
    "to learm more the about the interaction of electromagnetic waves at different frequencies with different substances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "The goal is to build a classification method that classifies substances based on their corresponding spectrograms. Each spectrogram has two dimensions, namely time and frequency. We treat the frequency dimension as input features to the reservoir. The output of the reservoir is then used to build a linear model. The labels are the 14 substances in the dataset. We used 80\\% of spectrograms, uniformly chosen across the 14 substances, as training set. The rest was used for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset consists of spectrograms of 14 substances. For each substance, there is about 650 spectrograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We start by importing some libraries and define some parameters. A utility function is defined to measure the runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "from functools import wraps\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from bumblebee_client.bumblebee_client import BumblebeeClient\n",
    "\n",
    "DATA_DIR = \"/shared/spectro/data\"\n",
    "NUM_SUBSTANCES = 14\n",
    "NUM_NODES = 2500 # Number of reservoir nodes\n",
    "TEST_SIZE_RATIO = 0.2 # Ratio of test data\n",
    "\n",
    "IP_ADDR = \"172.18.41.70\" # The api address of EmuCore \n",
    "VBIAS = 0.3 # Bias\n",
    "GAIN = 0.65 # Gain\n",
    "FEATURE_SCALING = 0.5 # Scaling coefficient for the input to reservoir\n",
    "\n",
    "def timer(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        beg_time = time.time()\n",
    "        val = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        tot_time = end_time - beg_time\n",
    "\n",
    "        print(\"Runtime of %s: %0.2f seconds!\" % (func.__name__, tot_time,))\n",
    "\n",
    "        return val\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Spectrograms and Labels\n",
    "\n",
    "We can then define a function that reads the dataset and splits it into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specs_labels(data_dir=DATA_DIR):\n",
    "\n",
    "    train_spec_list = []\n",
    "    train_label_list = []\n",
    "    train_spec_type_list = []\n",
    "    test_spec_list = []\n",
    "    test_label_list = []\n",
    "    test_spec_type_list = []\n",
    "    for i in range(NUM_SUBSTANCES):\n",
    "\n",
    "        i_str = \"{:02n}\".format(i + 1)\n",
    "        cache = np.load(\n",
    "            os.path.join(data_dir, \"substance%s.npy\" % i_str),\n",
    "            allow_pickle=True,\n",
    "        ).item()\n",
    "\n",
    "        for item in cache[\"pos\"].keys():\n",
    "\n",
    "            if random.random() > TEST_SIZE_RATIO:\n",
    "                train_spec_list.append(cache[\"pos\"][item])\n",
    "                train_label_list.append(i + 1)\n",
    "                train_spec_type_list.append(\"pos\")\n",
    "            else:\n",
    "                test_spec_list.append(cache[\"pos\"][item])\n",
    "                test_label_list.append(i + 1)\n",
    "                test_spec_type_list.append(\"pos\")\n",
    "\n",
    "    assert len(train_spec_list) == len(\n",
    "        train_label_list\n",
    "    ), \"Inconsistent sizes!\"\n",
    "    assert len(train_spec_list) == len(\n",
    "        train_spec_type_list\n",
    "    ), \"Inconsistent sizes!\"\n",
    "    assert len(test_spec_list) == len(\n",
    "        test_label_list\n",
    "    ), \"Inconsistent sizes!\"\n",
    "    assert len(test_spec_list) == len(\n",
    "        test_spec_type_list\n",
    "    ), \"Inconsistent sizes!\"\n",
    "\n",
    "    return (\n",
    "        train_spec_list,\n",
    "        train_label_list,\n",
    "        train_spec_type_list,\n",
    "        test_spec_list,\n",
    "        test_label_list,\n",
    "        test_spec_type_list,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through Reservoir\n",
    "\n",
    "We now define a function that gets the training and testing data and runs each spectrogram through the reservoir. The output of reservoir will be used to build a linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def run_reservoir(train_spec_list, test_spec_list, num_nodes):\n",
    "\n",
    "    num_taps = num_nodes\n",
    "    num_f = train_spec_list[0].shape[1]\n",
    "\n",
    "    for spec in train_spec_list:\n",
    "        spec.shape[1] == num_f, \"Inconsistent dimensions!\"\n",
    "\n",
    "    for spec in test_spec_list:\n",
    "        spec.shape[1] == num_f, \"Inconsistent dimensions!\"\n",
    "\n",
    "    # Padding the input vectors with zero before sending them through reservoir\n",
    "    zero_vec = np.zeros((10, num_f))\n",
    "\n",
    "    train_resp_list = []\n",
    "    for spec in train_spec_list:\n",
    "        \n",
    "        client = BumblebeeClient(ip_addr=IP_ADDR)\n",
    "        lock_id, start, end = client.wait_for_lock()\n",
    "        client.reservoir_reset(lock_id=lock_id)\n",
    "        client.rc_config(\n",
    "            lock_id=lock_id,\n",
    "             vbias=VBIAS,\n",
    "             gain=GAIN,\n",
    "             num_nodes=num_nodes,\n",
    "             num_taps=num_taps\n",
    "        )\n",
    "\n",
    "        resp, _, _ = client.process_all_data(\n",
    "            input_data=np.concatenate([zero_vec, spec], axis=0),\n",
    "            num_nodes=num_nodes,\n",
    "            density=1,\n",
    "            feature_scaling=FEATURE_SCALING,\n",
    "            lock_id=lock_id,\n",
    "        )\n",
    "        client.release_lock(lock_id=lock_id)\n",
    "        \n",
    "        train_resp_list.append(resp)\n",
    "\n",
    "    test_resp_list = []\n",
    "    for spec in test_spec_list:\n",
    "\n",
    "        client = BumblebeeClient(ip_addr=IP_ADDR)\n",
    "        lock_id, start, end = client.wait_for_lock()\n",
    "        client.reservoir_reset(lock_id=lock_id)\n",
    "        client.rc_config(\n",
    "            lock_id=lock_id,\n",
    "             vbias=VBIAS,\n",
    "             gain=GAIN,\n",
    "             num_nodes=num_nodes,\n",
    "             num_taps=num_taps\n",
    "        )\n",
    "\n",
    "        resp, _, _ = client.process_all_data(\n",
    "            input_data=np.concatenate([zero_vec, spec], axis=0),\n",
    "            num_nodes=num_nodes,\n",
    "            density=DENSITY,\n",
    "            feature_scaling=FEATURE_SCALING,\n",
    "            lock_id=lock_id,\n",
    "        )\n",
    "        client.release_lock(lock_id=lock_id)\n",
    "            \n",
    "        test_resp_list.append(resp)\n",
    "\n",
    "    return train_resp_list, test_resp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Classifier\n",
    "\n",
    "Finally, we define a function that builds a linear classifier. Note that when \"reservoir_flag\" is set to False, the reservoir step is skipped and a linear classifier is build based on the raw spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def build_classifier(reservoir_flag=True):\n",
    "\n",
    "    (\n",
    "        train_spec_list,\n",
    "        train_label_list,\n",
    "        train_spec_type_list,\n",
    "        test_spec_list,\n",
    "        test_label_list,\n",
    "        test_spec_type_list,\n",
    "    ) = get_specs_labels()\n",
    "\n",
    "    train_resp_list = train_spec_list\n",
    "    test_resp_list = test_spec_list\n",
    "    \n",
    "    if reservoir_flag:\n",
    "        train_resp_list, test_resp_list = run_reservoir(\n",
    "            train_spec_list, test_spec_list, NUM_NODES, \n",
    "        )\n",
    "\n",
    "    X_train = np.concatenate(train_resp_list, axis=0)\n",
    "    X_test = np.concatenate(test_resp_list, axis=0)\n",
    "\n",
    "    y_train = []\n",
    "    for i, spec in enumerate(train_resp_list):\n",
    "        tmp_list = [train_label_list[i]] * spec.shape[0]\n",
    "        y_train += tmp_list\n",
    "\n",
    "    y_test = []\n",
    "    for i, spec in enumerate(test_resp_list):\n",
    "        tmp_list = [test_label_list[i]] * spec.shape[0]\n",
    "        y_test += tmp_list\n",
    "\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(y_train.reshape(-1, 1))\n",
    "\n",
    "    y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "    y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "    y_train = 2.0 * y_train - 1.0\n",
    "    y_test = 2.0 * y_test - 1.0\n",
    "\n",
    "    assert X_train.shape[0] == y_train.shape[0], \"Inconsistent sizes!\"\n",
    "    assert X_test.shape[0] == y_test.shape[0], \"Inconsistent sizes!\"\n",
    "    assert y_train.shape[1] == NUM_SUBSTANCES, \"Inconsistent sizes!\"\n",
    "    assert y_test.shape[1] == NUM_SUBSTANCES, \"Inconsistent sizes!\"\n",
    "\n",
    "    clf = LinearRegression(fit_intercept=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    score = clf.score(X_train, y_train)\n",
    "    print(\"Regression Score = %f\" % (score))\n",
    "\n",
    "    success = 0\n",
    "    count = 0\n",
    "    for i, spec in enumerate(train_resp_list):\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        act_label = int(train_label_list[i])\n",
    "\n",
    "        tmp_vec = clf.predict(spec).mean(axis=0)\n",
    "        tmp_vec = 1 * (tmp_vec == np.amax(tmp_vec))\n",
    "        prd_label = enc.inverse_transform(tmp_vec.reshape(1, -1))[0][0]\n",
    "\n",
    "        if prd_label == act_label:\n",
    "            success += 1\n",
    "\n",
    "    print(\"Success rate on train data: %0.3f\" % (success / count))\n",
    "\n",
    "    success = 0\n",
    "    count = 0\n",
    "    for i, spec in enumerate(test_resp_list):\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        act_label = int(test_label_list[i])\n",
    "\n",
    "        tmp_vec = clf.predict(spec).mean(axis=0)\n",
    "        tmp_vec = 1 * (tmp_vec == np.amax(tmp_vec))\n",
    "        prd_label = enc.inverse_transform(tmp_vec.reshape(1, -1))[0][0]\n",
    "\n",
    "        if prd_label == act_label:\n",
    "            success += 1\n",
    "\n",
    "    print(\"Success rate on test data: %0.3f\" % (success / count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then call the above function to run the process from end to end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_classifier(reservoir_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Classifiers were built using different number of reservoir nodes on QCi's EmuCore. \n",
    "\n",
    "The table below shows the success rates (on both training and testing data) of classifiers built when different numbers of reservoir nodes are used. A \"0\" number of reservoir nodes corresponds to the case where no reservoir was used and a linear model was trained based on the raw spectrograms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"success_rate_substance_classification.png\" alt=\"fishy\" class=\"bg-primary mb-1\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next table shows the training times of the classifiers using different numbers of nodes. As can been seen, the training time increases more or less linearly with number of nodes used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"runtime_substance_classification.png\" alt=\"fishy\" class=\"bg-primary mb-1\" width=\"600px\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
