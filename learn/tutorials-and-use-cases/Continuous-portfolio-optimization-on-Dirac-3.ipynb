{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOj5zv2MppGD"
   },
   "source": [
    "# Continuous Portfolio Optimization\n",
    "\n",
    "#### Device: Dirac-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This approach seeks to identify a sub-portfolio of stocks that have superior risk-return profiles compared to the full portfolio. This identifies opportunities for an investor to simplify their investment strategy without sacrificing (and potentially enhancing) the risk-adjusted return. While the expected return on a portfolio is relatively straightforward to optimize by itself, optimizing against risk is more subtle when choosing a set of assets that individually have high returns. The reason that optimizing against risk is more challenging is because asset performances can be correlated. Intuitively, one can see that investing in two highly-correlated assets is more risky than if they are uncorrelated or even anti-correlated. If one of a highly correlated asset is performing poorly, the other in the pair is likely to do so as well. Thus, the variance of a portfolio with both assets can be significantly higher than it would be if they were uncorrelated. Minimizing the overall variance for the return of a portfolio therefore needs to take into account the covariance between the assets, making this a fundamentally quadratic problem, ideal for our Dirac-1 solver.\n",
    "\n",
    "## Importance\n",
    "\n",
    "Investments need not only give a good return on average, but also need to balance the potential risks. This balance will depend on the goal of the investor. For example, someone investing their retirement fund is likely to favor modest returns with low risks because the consequences of major losses are severe. On the other hand, someone who is day-trading in the hopes of having more money for entertainment might be willing to take more risks. There are of course many other scenarios with other risk levels. In general, the portfolio optimization problem is viewed as being a multi-objective problem. The goal is to balance the objective of maximizing return with the objective of minimizing risk. Even with multiple objectives there is still a sense of optimality, a portfolio is said to be \"efficient\" or \"[Pareto optimal](https://en.wikipedia.org/wiki/Multi-objective_optimizationy)\" if the only ways to decrease risk would be to also decrease return. Regardless of one's appetite for risk, it never makes sense to invest in a non-Pareto-Optimal portfolio, so our goal is to find those that are Pareto optimal and match the appetite for risk which is parameterized by a term  $\\xi$ in our description. It is worth noting that this tutorial is based on a relatively simplified but still commonly used model of portfolio optimization. Various efforts exist to take into account more complex structure in the distribution of expected returns, in particular [the failure to capture extreme events](http://math.bu.edu/people/murad/pub/hist11-posted.pdf).\n",
    "\n",
    "## Applications\n",
    "\n",
    "Portfolios diversification is necessary to achieve satisfactory outcomes for investors, making the kind of portfolio optimization discussed here (and potentially more complex variants) highly important. In spite of its simplicity, the model of diversification presented here, often referred to as [modern portfolio](https://www.britannica.com/money/modern-portfolio-theory-explained) theory, is [still used](https://www.nutmeg.com/nutmegonomics/markowitzs-legacy-why-modern-portfolio-theory-still). Improvements of the models presented here comprise a subject known as [post-modern portfolio theory](http://actuaries.org/AFIR/Colloquia/Orlando/Ferguson_Rom.pdf). One improvement is to consider a quantity known as [downside risk](https://www.lehigh.edu/~xuy219/research/Downside.pdf) instead of variance. Downside risk only takes into account the risk of portfolio elements underperforming a goal, rather than their total variation. Since the goal of diversification is to protect from risk, this approach can yield better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous optimization helps in selecting and determining how much to invest in each stock. Unlike binary optimization, where you decide whether to include a stock or not (1 or 0), continuous optimization allows for more precise investment decisions by assigning continuous values to represent the proportion of your investment in each stock. This method helps create a well-diversified portfolio with varying levels of investment in different stocks to better manage risk and achieve desired returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "KXCYfzyDjCG7",
    "outputId": "0171d1a7-82f6-4208-ac11-728bbd81137f"
   },
   "source": [
    "![weighted stocks](figures/continuous/01.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yq1Sv3yqgyg"
   },
   "source": [
    "## Constructing our Objective Function\n",
    "\n",
    "In our tutorial, we have historical datasets containing stock prices over a period of time. Our goal is to use these datasets to calculate important metrics such as [the rate of return](https://en.wikipedia.org/wiki/Rate_of_return), [expected return](https://en.wikipedia.org/wiki/Expected_return), [variance](https://en.wikipedia.org/wiki/Variance), and [covariance](https://en.wikipedia.org/wiki/Covariance). By calculating these metrics for each stock in our portfolio, we gain insights into their performance and risk characteristics. Expected return helps us gauge potential profitability, variance quantifies the risk associated with individual stocks, and covariance indicates how stocks move relative to each other. These calculations are essential for making informed investment decisions aimed at optimizing returns while managing risk effectively.\n",
    "\n",
    "\n",
    "We define the following variables as:\n",
    "\n",
    "**1. $i$:** Index of stock\n",
    "\n",
    "**2. K:** Total number of available stocks in given portfolio.\n",
    "\n",
    "**3. R:** Daily returns or the Returns per Day of the portfolio\n",
    "\n",
    "**4. E(R):** Expected Return of the portfolio\n",
    "\n",
    "**5. Var(R):** Variance of portfolio's returns\n",
    "\n",
    "**6. $\\xi$:** A parameter that balances the importance of maximizing returns versus minimizing risk.\n",
    "\n",
    "**7. $R_b$:** Base interest rate.e; it is introduced so that the\n",
    "two added terms in the objective function are on an equal footing.\n",
    "\n",
    "**8. $w_i$:**  Weight of\n",
    "stock i in the portfolio; $i \\in {1, 2, ..., K}$\n",
    "\n",
    "\n",
    "Now, we can define our **Objective Function**, i.e, the function that encapsulates the goal of constructing a portfolio that balances maximizing expected returns and minimizing risk.   as follows:\n",
    "\n",
    "\n",
    "$$ \\text{min}_{\\{w_i\\}_{i\\in \\{1,2,..k\\}}}   -E(R) \\cdot R_b + \\xi\\cdot \\text{Var}(R) $$\n",
    "\n",
    "\n",
    "\n",
    "We want our weights to sum to $100%$, therefore:\n",
    "\n",
    "$$ \\sum_{i=1}^k w_i = 100 $$\n",
    "\n",
    "\n",
    "\n",
    "We also want the portfolio to be diverse, so we apply an upper limit on all the weights:\n",
    "\n",
    "$$ w_i \\leq W_{\\text{max}} $$\n",
    "\n",
    "In our example we set our  upper limit on all the weights $W_{\\text{max}}$ equal to $80$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOwzVZy2vj63"
   },
   "source": [
    "## Hamiltonian Construction\n",
    "\n",
    "We are going to get into more rigorous math in this section. So you can feel free to skip to the next section to understand the code flow and observe the results!\n",
    "\n",
    "\n",
    "The portfolio daily return over a time period $m$ can be written as a linear combination of daily returns of its constituent stocks over the same time period. We have,\n",
    "\n",
    "$$ R^{(m)}(t) = \\sum_{i = 1}^K w_i r_i ^{(m)}(t) $$\n",
    "\n",
    "where, $r_i ^{(m)}(t)$ is the daily return of stock $i$ at time $t$ during time period $m$.\n",
    "\n",
    "The expectation of portfolio daily return over time period $m$ can thus be expanded as:\n",
    " $$ E(R^{(m)}) = \\sum_{i = 1}^K w_i E(r_i ^{(m)}) $$\n",
    "\n",
    "and the variance of portfolio daily returns over time period $m$ is expanded as,\n",
    "\n",
    "$$ \\text{Var}(R^{(m)}) = \\sum_{i = 1}^K \\sum_{j = 1}^K w_i w_j \\text{Covar}(r_i ^{(m)},r_j ^{(m)}) $$\n",
    "\n",
    "where Covar is the covariance function.\n",
    "\n",
    "\n",
    "\n",
    "To impose the inequality constraints in $ w_i \\leq W_{\\text{max}}$, we can introduce $K$ auxiliary variables\n",
    "$ w_{K+1}, w_{K+2}, ..., w_{2K} $, and impose $K$ equality constraints as,\n",
    "\n",
    "$$ w_i + w_{i+K} = W_{\\text{max}} $$\n",
    "\n",
    "\n",
    "Substituting Equations for daily expectation of portfolio daily return over time period $m$ and variance of portfolio daily returns over time period $m$ into Equation 2, the objective function, that we now call $f^{(m)},$ becomes:\n",
    "\n",
    "$$ f^{(m)}(w) = \\sum_{i,j = 1} ^K w_i A_{ij}^{(m)}w_j + \\sum_{i=1}^K w_ib_i^{(m)} + \\alpha(\\sum_{i=1}^K w_i - 100 )^2 + \\beta(\\sum_{i=1}^K (w_i + w_{i+K} - W_{\\text{max}})^2 $$\n",
    "\n",
    "where,\n",
    "\n",
    "$$ A^{(m)}_{ij} = \\xi\\cdot \\text{Covar}(r^{(m)}_i, r^{(m)}_j) $$\n",
    "\n",
    "$$ b^{(m)}_i = âˆ’R_B\\cdot E(r^{(m)}_i) $$\n",
    "\n",
    "\n",
    "To avoid an over-fit on the portfolio data, we can minimize the average of the cost function over $M$\n",
    "overlapping time periods, that is $m \\in {1, 2, ..., M}.$ The problem becomes,\n",
    "\n",
    "$$ f(w) =  \\frac{1}{M} \\sum_{m=1}^M f(w) $$\n",
    "\n",
    "\n",
    "Adding the constraints to the objective function, the optimization\n",
    "problem reduces to,\n",
    "\n",
    "$$ \\text{min}_{w_i} \\sum_{i=1}^{2K} \\sum_{j=1}^{2K} J_{ij} w_iw_j + \\sum_{i=1}^{2k}h_iw_i $$\n",
    "\n",
    "where the two body coupling coefficients $J_{ij}$ are defined as\n",
    "\n",
    "$$ J_{ij}= J_{ij}^\\mathrm{(obj)}+ \\beta J_{ij}^\\mathrm{(constr)} $$\n",
    "\n",
    "where and objective function component of the coupling is defined as\n",
    "\n",
    "$$ J_{ij}^\\mathrm{(obj)} = \n",
    "  \\begin{cases}\n",
    "    \\frac{1}{M} \\sum_{m=1}^M A_{ij}^{(m)} + \\alpha & \\quad \\text{if } i,j \\leq K \\\\\n",
    "    0 & \\quad \\text{otherwise}\n",
    "  \\end{cases} $$\n",
    "\n",
    "and a constraint component defined as\n",
    "\n",
    "$$ J_{ij}^\\mathrm{(constr)} = \n",
    "  \\begin{cases}\n",
    "    1 & \\quad \\text{if } i=j \\\\\n",
    "    1 & \\quad \\text{if } \\left|i-j\\right|=K \\\\\n",
    "    0 & \\quad \\text{otherwise}\n",
    "  \\end{cases} $$\n",
    "\n",
    "\n",
    "and the linear coefficients $h_i$ are defined as,\n",
    "\n",
    "$$ h_{i}= h_{i}^\\mathrm{(obj)}+ \\beta h_{i}^\\mathrm{(constr)} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ h_{i}^{(obj)} = \n",
    "  \\begin{cases}\n",
    "    b_i - 200\\alpha & \\quad \\text{if } i \\leq K \\\\\n",
    "    0 & \\text{otherwise}\n",
    "  \\end{cases} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ h_{i}^{(constr)} = - 2 W_{\\text{max}} \\quad \\forall i $$\n",
    "\n",
    "The Hamiltonian equation becomes:\n",
    "\n",
    "\n",
    "$$ H = [ h \\mid \\frac{1}{2} (J + J^T)] $$\n",
    "\n",
    "where:\n",
    "\n",
    "- $( 0.5 \\cdot (J + J^T) )$ represents the symmetrized form of $J$\n",
    "- The notation $h \\mid \\frac{1}{2} (J + J^T)$ denotes the horizontal concatenation of $h$ and $\\frac{1}{2} (J + J^T)$, in other words the addition of $h$ as a column of the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-U6kYmb_org"
   },
   "source": [
    "# Understanding the Code with an Example\n",
    "\n",
    "Before we begin, you'll need your unique token to access the QCi Client API and connect to the Dirac device. If you don't have a token yet, you can sign up for our [Free Trial Cloud Access](https://quantumcomputinginc.com/learn/tutorials-and-use-cases/quick-start-on-cloud)). Let's get started!\n",
    "\n",
    "You can download the data sets and get access to the full code base [here](https://git.qci-dev.com/cvadlamani/basic-catalyst-tutorial/-/tree/Chitra/integer_portfolio_optimization?ref_type=heads)\n",
    "\n",
    "Imagine you have  $5$  stocks in your portfolio and you want to find the optimized portfolio weights\n",
    "\n",
    "Here are 5 stocks present in our portfolio, let us see how we can optimize them using our Run() method:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Stock</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>AAPL</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>AMZN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>GOOG</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>MSFT</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>NVDA</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "## Run () method\n",
    "\n",
    "The *run function* is the main function of the portfolio optimization pipeine that performs a series of operations to analyze stock data and optimize a stock portfolio based on historical returns.\n",
    "\n",
    "It does three main things: first, it retrieves the stock data. Then it preprocesses the data and  constructs a Hamiltonian matrix to balance returns and risks. Finally, it optimizes the stock portfolio and the function ultimately saves the stock allocation data to a specified CSV file and displays the optimized portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a dump of functions from the gitlab, this may not be the best place for them but want to get all the code into the notebook with some initial efforts to clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from qci_client import QciClient\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = \"https://api.qci-prod.com\"\n",
    "api_token = \"token goes here\"\n",
    "client = QciClient(api_token=api_token, url=api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scJzDeQJKPsV"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###### parameters #######\n",
    "\n",
    "DROP_STOCKS = []\n",
    "ALPHA = 5.0\n",
    "BETA = 1.0\n",
    "XI = 1.0\n",
    "WINDOW_DAYS = 30\n",
    "WINDOW_OVERLAP_DAYS = 15\n",
    "IN_SAMPLE_DAYS = 60\n",
    "OUT_OF_SAMPLE_DAYS = 30\n",
    "WEIGHT_UPPER_LIMIT = 0.08\n",
    "R_BASE = 0.05 / 365\n",
    "\n",
    "MIN_DATE = pd.to_datetime(\"2023-06-15\") \n",
    "MAX_DATE = pd.to_datetime(\"2024-03-31\")\n",
    "\n",
    "ALLOC_OUT_FILE = (\n",
    "    \"data/unequal_stock_allocations_xi_%s_wd_%d_olap_%d_ins_%d_oos_%d_dirac3_s2_rel1.csv\"\n",
    "    % (\n",
    "        str(XI),\n",
    "        WINDOW_DAYS,\n",
    "        WINDOW_OVERLAP_DAYS,\n",
    "        IN_SAMPLE_DAYS,\n",
    "        OUT_OF_SAMPLE_DAYS,\n",
    "    )\n",
    ")\n",
    "\n",
    "######## end parameters ####\n",
    "\n",
    "\n",
    "def convert_hamiltonian_to_poly(J, h):\n",
    "    import numpy as np\n",
    "    assert J.shape[0] == J.shape[1]\n",
    "\n",
    "    N = J.shape[0]\n",
    "    poly_coefs = []\n",
    "    poly_indices = []\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            if i == j:\n",
    "                coef = J[i][j]\n",
    "            elif i < j:\n",
    "                coef = J[i][j] + J[j][i]\n",
    "            else:\n",
    "                assert False, \"Incorrect indices!\"\n",
    "\n",
    "            if coef == 0.0:\n",
    "                continue\n",
    "\n",
    "            poly_coefs.append(coef)\n",
    "            poly_indices.append([i + 1, j + 1])\n",
    "\n",
    "    for i in range(N):\n",
    "        coef = h[i]\n",
    "\n",
    "        if coef == 0.0:\n",
    "            continue\n",
    "\n",
    "        poly_coefs.append(coef)\n",
    "        poly_indices.append([0, i + 1])\n",
    "\n",
    "    assert len(poly_coefs) == len(poly_indices)\n",
    "\n",
    "    poly_coefs = np.array(poly_coefs, dtype=np.float32)\n",
    "    poly_indices = np.array(poly_indices, dtype=np.int32)\n",
    "\n",
    "    return poly_coefs, poly_indices\n",
    "\n",
    "\n",
    "def get_constituents(adj_date):\n",
    "    import pandas as pd\n",
    "    from parameters import DROP_STOCKS\n",
    "    from remove_unavailable_stocks import remove_unavailable_stocks\n",
    "    adj_date = pd.to_datetime(adj_date)\n",
    "    file_path = \"data/stock_data.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    #df = pd.read_csv(\"data/stock_data.csv\", low_memory=False)\n",
    "\n",
    "    df[\"beg_date\"] = df[\"beg_date\"].apply(pd.to_datetime)\n",
    "\n",
    "    beg_dates = sorted(df[\"beg_date\"].unique(), reverse=True)\n",
    "\n",
    "    for beg_date in beg_dates:\n",
    "        if adj_date >= beg_date:\n",
    "            break\n",
    "\n",
    "    stocks = list(df[df[\"beg_date\"] == beg_date][\"symbol\"].unique())\n",
    "    stocks = list(set(stocks) - set(DROP_STOCKS))\n",
    "    stocks = remove_unavailable_stocks(stocks, adj_date)\n",
    "\n",
    "    return stocks\n",
    "    \n",
    "\n",
    "def get_hamiltonian(\n",
    "    return_df,\n",
    "    stocks,\n",
    "    min_date,\n",
    "    max_date,\n",
    "    xi=XI,\n",
    "    window_days=WINDOW_DAYS,\n",
    "    window_overlap_days=WINDOW_OVERLAP_DAYS,\n",
    "):\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    import pandas as pd\n",
    "    from parameters import R_BASE, WEIGHT_UPPER_LIMIT, ALPHA, BETA\n",
    "    K = len(stocks)\n",
    "\n",
    "    # Calculate P and Q\n",
    "    Q = np.zeros(shape=(K, K), dtype=np.float32)\n",
    "    #P = np.zeros(shape=(K, K), dtype=np.float32)\n",
    "    p_vec = np.zeros(shape=(K), dtype=np.float32)\n",
    "    \n",
    "    m = 0\n",
    "    min_date = pd.to_datetime(min_date)\n",
    "    max_date = pd.to_datetime(max_date)\n",
    "    tmp_date = min_date\n",
    "    while tmp_date <= max_date:\n",
    "        tmp_min_date = tmp_date\n",
    "        tmp_max_date = tmp_date + datetime.timedelta(days=window_days)\n",
    "        tmp_df = return_df[\n",
    "            (return_df[\"Date\"] >= tmp_min_date)\n",
    "            & (return_df[\"Date\"] <= tmp_max_date)\n",
    "        ]\n",
    "\n",
    "        r_list = []\n",
    "        for i in range(K):\n",
    "            r_list.append(np.array(tmp_df[stocks[i]]))\n",
    "\n",
    "        Q_tmp = np.cov(r_list)\n",
    "        for i in range(K):\n",
    "            p_vec[i] += -R_BASE * np.mean(r_list[i])             \n",
    "            for j in range(K):\n",
    "                #P[i][j] += np.mean(r_list[i]) * np.mean(r_list[j])\n",
    "\n",
    "                Q[i][j] += Q_tmp[i][j]\n",
    "\n",
    "        tmp_date += datetime.timedelta(\n",
    "            days=window_days - window_overlap_days,\n",
    "        )\n",
    "        m += 1\n",
    "\n",
    "    fct = m\n",
    "    if fct > 0:\n",
    "        fct = 1.0 / fct\n",
    "\n",
    "    #P = fct * P\n",
    "    p_vec = fct * p_vec\n",
    "    Q = fct * Q\n",
    "\n",
    "    # Calculate the Hamiltonian\n",
    "    #J_no_limit = -P + xi * Q\n",
    "    J_no_limit = xi * Q\n",
    "\n",
    "    # make sure J is symmetric up to machine precision\n",
    "    J_no_limit = 0.5 * (J_no_limit + J_no_limit.transpose())\n",
    "\n",
    "    #h_no_limit = np.zeros(shape=(K), dtype=np.float32)\n",
    "    h_no_limit = p_vec\n",
    "    \n",
    "    if WEIGHT_UPPER_LIMIT is None:\n",
    "        return J_no_limit, h_no_limit, 100.0\n",
    "\n",
    "    W_max = 100.0 * WEIGHT_UPPER_LIMIT\n",
    "\n",
    "    J = np.zeros(shape=(2 * K, 2 * K), dtype=np.float32)\n",
    "    h = np.zeros(shape=(2 * K), dtype=np.float32)\n",
    "\n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            J[i][j] = J_no_limit[i][j] + ALPHA\n",
    "\n",
    "        J[i][i] += BETA\n",
    "        J[i][i + K] += BETA\n",
    "        J[i + K][i] += BETA\n",
    "        J[i + K][i + K] += BETA\n",
    "\n",
    "        h[i] = h_no_limit[i] - 200.0 * ALPHA - 2 * BETA * W_max\n",
    "        h[i + K] = -2 * BETA * W_max\n",
    "\n",
    "    return J, h, K * W_max\n",
    "\n",
    "\n",
    "def get_stock_returns(stocks, min_date, max_date):\n",
    "    import pandas as pd\n",
    "    min_date = pd.to_datetime(min_date)\n",
    "    max_date = pd.to_datetime(max_date)\n",
    "    return_df = None\n",
    "    for stock in stocks:\n",
    "    \n",
    "        stock_df = pd.read_csv(\"data/stock_prices/%s.csv\" % stock)\n",
    "        stock_df[\"Date\"] = stock_df[\"Date\"].astype(\"datetime64[ns]\")\n",
    "        stock_df = (\n",
    "            stock_df.fillna(method=\"ffill\")\n",
    "            .fillna(method=\"bfill\")\n",
    "            .fillna(0)\n",
    "        )\n",
    "        stock_df[stock] = stock_df[stock].pct_change()\n",
    "        stock_df = stock_df.dropna()\n",
    "\n",
    "        stock_df = stock_df[\n",
    "            (stock_df[\"Date\"] >= min_date) & (stock_df[\"Date\"] <= max_date)\n",
    "        ]\n",
    "\n",
    "        if return_df is None:\n",
    "            return_df = stock_df\n",
    "        else:\n",
    "            return_df = return_df.merge(\n",
    "                stock_df,\n",
    "                how=\"outer\",\n",
    "                on=\"Date\",\n",
    "            )\n",
    "\n",
    "    return_df = (\n",
    "        return_df.fillna(method=\"ffill\").fillna(method=\"bfill\").fillna(0)\n",
    "    )\n",
    "\n",
    "    return return_df\n",
    "\n",
    "def optimize_portfolio(J, h, sum_constraint, stocks, client):\n",
    "\n",
    "    \n",
    "\n",
    "    K = len(stocks)\n",
    "\n",
    "    assert J.shape[0] == K or J.shape[0] == 2 * K\n",
    "    assert J.shape[1] == K or J.shape[0] == 2 * K\n",
    "    assert h.shape[0] == K or h.shape[0] == 2 * K\n",
    "\n",
    "\n",
    "    h = h.reshape((h.shape[0], 1))\n",
    "    H = np.hstack((h, 0.5 * (J + J.T)))\n",
    "\n",
    "    ham_file = {\n",
    "        \"file_name\": \"port_opt_nasdaq100_d3\",\n",
    "        \"file_config\": {\"hamiltonian\": {\"data\": H}},\n",
    "    }\n",
    "\n",
    "    resp_json = client.upload_file(file=ham_file)\n",
    "    file_id = resp_json[\"file_id\"]\n",
    "    job_tags = [\"port_opot_nasdaq100_d3\"]\n",
    "    job_body = client.build_job_body(\n",
    "        job_type=\"sample-hamiltonian\",\n",
    "        hamiltonian_file_id=file_id,\n",
    "        job_params={\n",
    "            \"sampler_type\": \"dirac-3\",\n",
    "            \"nsamples\": 1,\n",
    "            \"solution_type\": \"continuous\",\n",
    "            \"sum_constraint\": sum_constraint,\n",
    "            \"relaxation_schedule\": 1,\n",
    "        },\n",
    "        job_tags=job_tags,\n",
    "    )\n",
    "    response = client.process_job(\n",
    "        job_body=job_body,\n",
    "        wait=True,\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "    sol = response[\"results\"][\"solutions\"][0]\n",
    "\n",
    "    assert (\n",
    "        len(sol) == K or len(sol) == 2 * K\n",
    "    ), \"Inconsistent solution vector size!\"\n",
    "\n",
    "    weight_hash = {}\n",
    "    for i in range(K):\n",
    "        weight_hash[stocks[i]] = sol[i] / 100.0\n",
    "\n",
    "    tot_weight = sum(weight_hash.values())\n",
    "\n",
    "    print(\"Sum of weights:\", tot_weight)\n",
    "\n",
    "    if tot_weight != 1.0:\n",
    "        print(\"Adjusting the weights...\")\n",
    "\n",
    "        for stock in stocks:\n",
    "            weight_hash[stock] = weight_hash[stock] / tot_weight\n",
    "\n",
    "    print(\"Adjusted weights:\", weight_hash)\n",
    "\n",
    "\n",
    "    return sol, weight_hash\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_unavailable_stocks(stocks, adj_date):\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    from parameters import IN_SAMPLE_DAYS, OUT_OF_SAMPLE_DAYS\n",
    "    sel_stocks = []\n",
    "    for stock in stocks:\n",
    "        stock_df = pd.read_csv(\"data/stock_prices/%s.csv\" % stock)\n",
    "\n",
    "        if stock_df.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        stock_df[\"Date\"] = stock_df[\"Date\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "        adj_date = pd.to_datetime(adj_date)\n",
    "        beg_date = adj_date - datetime.timedelta(days=IN_SAMPLE_DAYS)\n",
    "        end_date = adj_date + datetime.timedelta(days=OUT_OF_SAMPLE_DAYS)\n",
    "\n",
    "        stock_df = stock_df[\n",
    "            (stock_df[\"Date\"] >= beg_date) &\n",
    "            (stock_df[\"Date\"] <= end_date)\n",
    "        ]\n",
    "\n",
    "        if stock_df.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        sel_stocks.append(stock)\n",
    "\n",
    "    print(\"Chose %d of %d stocks\" % (len(sel_stocks), len(stocks)))\n",
    "\n",
    "    return sel_stocks\n",
    "\n",
    "\n",
    "def remove_unavailable_stocks(stocks, adj_date):\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    from parameters import IN_SAMPLE_DAYS, OUT_OF_SAMPLE_DAYS\n",
    "    sel_stocks = []\n",
    "    for stock in stocks:\n",
    "        stock_df = pd.read_csv(\"stock_prices/%s.csv\" % stock)\n",
    "\n",
    "        if stock_df.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        stock_df[\"Date\"] = stock_df[\"Date\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "        adj_date = pd.to_datetime(adj_date)\n",
    "        beg_date = adj_date - datetime.timedelta(days=IN_SAMPLE_DAYS)\n",
    "        end_date = adj_date + datetime.timedelta(days=OUT_OF_SAMPLE_DAYS)\n",
    "\n",
    "        stock_df = stock_df[\n",
    "            (stock_df[\"Date\"] >= beg_date) &\n",
    "            (stock_df[\"Date\"] <= end_date)\n",
    "        ]\n",
    "\n",
    "        if stock_df.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        sel_stocks.append(stock)\n",
    "\n",
    "    print(\"Chose %d of %d stocks\" % (len(sel_stocks), len(stocks)))\n",
    "\n",
    "    return sel_stocks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "oElJA52V5x5T",
    "outputId": "84f263fc-dd81-405b-df34-3ee7e0c851ac"
   },
   "source": [
    "![flow diagram](figures/continuous/02.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwvQr05H51Vk"
   },
   "source": [
    "## Step 1\n",
    "\n",
    "Initialize and Prepare Dates:\n",
    "* Calculates the in-sample date range based on the current date for historical data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date  = pd.to_datetime(current_date )\n",
    "in_sample_start_date  = current_date  - datetime.timedelta(days=in_sample_days)\n",
    "in_sample_end_date  = current_date - datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve Stock Data:\n",
    "* Obtains the list of stock constituents as of the current_date.\n",
    "* Fetches historical stock returns for the in-sample period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = get_constituents(current_date)\n",
    "in_sample_returns_df  = get_stock_returns(stocks, in_sample_start_date, in_sample_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2xBO_bO6Ur9"
   },
   "source": [
    "## Step 2\n",
    "Preprocess Data:\n",
    "* Sorts the stock return data by date.\n",
    "* Fills any missing values in the stock return data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_returns_df  = in_sample_returns_df.sort_values(\"Date\")\n",
    "in_sample_returns_df  = in_sample_returns_df.fillna(method=\"ffill\").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDnHpL-O6etc"
   },
   "source": [
    "## Step 3\n",
    "Calculates Elements of Hamiltonian\n",
    "* Computes the elements $J$ and $h$, and a sum constraint using the in-sample stock returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J, h, sum_constraint = get_hamiltonian(\n",
    "    in_sample_returns_df,\n",
    "    stocks,\n",
    "    in_sample_start_date ,\n",
    "    in_sample_end_date ,\n",
    ")\n",
    "\n",
    "#np.save(\"J_%s.npy\" % current_date.strftime(\"%Y-%m-%d\"), J)\n",
    "#np.save(\"h_%s.npy\" % current_date.strftime(\"%Y-%m-%d\"), h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQekKfA1636o"
   },
   "source": [
    "## Step 4\n",
    "* Optimize Portfolio:\n",
    "  * Creates Hamiltonian using Hamiltonian data.\n",
    "  * Runs a portfolio optimization algorithm using the Hamiltonian.\n",
    "  * Saves the optimization results and stock list to files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  optimized_weights , stock_allocations = optimize_portfolio(J, h, sum_constraint, stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBUMeexqEC4r"
   },
   "source": [
    "The result JSON file looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_info': {'job_id': '6679944a450099160ba0bf88',\n",
       "  'job_submission': {'job_tags': ['port_opot_nasdaq100_d3'],\n",
       "   'problem_config': {'normalized_qudit_hamiltonian_optimization': {'hamiltonian_file_id': '6679944a98263204a365f329'}},\n",
       "   'device_config': {'dirac-3': {'num_samples': 1,\n",
       "     'relaxation_schedule': 1,\n",
       "     'sum_constraint': 40}}},\n",
       "  'job_status': {'submitted_at_rfc3339nano': '2024-06-24T15:44:10.523Z',\n",
       "   'queued_at_rfc3339nano': '2024-06-24T15:44:10.524Z',\n",
       "   'running_at_rfc3339nano': '2024-06-24T15:44:11.514Z',\n",
       "   'completed_at_rfc3339nano': '2024-06-24T15:44:13.339Z'},\n",
       "  'job_result': {'file_id': '6679944d98263204a365f32b', 'device_usage_s': 2}},\n",
       " 'status': 'COMPLETED',\n",
       " 'results': {'counts': [1],\n",
       "  'energies': [-32319.5527344],\n",
       "  'solutions': [[8.0512924,\n",
       "    7.9148078,\n",
       "    7.9524417,\n",
       "    7.9162955,\n",
       "    8.1651621,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0]]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"job_info\": {\n",
    "    \"job_id\": \"6679944a450099160ba0bf88\",\n",
    "    \"job_submission\": {\n",
    "      \"job_tags\": [\"port_opot_nasdaq100_d3\"],\n",
    "      \"problem_config\": {\n",
    "        \"normalized_qudit_hamiltonian_optimization\": {\n",
    "          \"hamiltonian_file_id\": \"6679944a98263204a365f329\"\n",
    "        }\n",
    "      },\n",
    "      \"device_config\": {\n",
    "        \"dirac-3\": {\n",
    "          \"num_samples\": 1,\n",
    "          \"relaxation_schedule\": 1,\n",
    "          \"sum_constraint\": 40\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"job_status\": {\n",
    "      \"submitted_at_rfc3339nano\": \"2024-06-24T15:44:10.523Z\",\n",
    "      \"queued_at_rfc3339nano\": \"2024-06-24T15:44:10.524Z\",\n",
    "      \"running_at_rfc3339nano\": \"2024-06-24T15:44:11.514Z\",\n",
    "      \"completed_at_rfc3339nano\": \"2024-06-24T15:44:13.339Z\"\n",
    "    },\n",
    "    \"job_result\": {\n",
    "      \"file_id\": \"6679944d98263204a365f32b\",\n",
    "      \"device_usage_s\": 2\n",
    "    }\n",
    "  },\n",
    "  \"status\": \"COMPLETED\",\n",
    "  \"results\": {\n",
    "    \"counts\": [1],\n",
    "    \"energies\": [-32319.5527344],\n",
    "    \"solutions\": [\n",
    "      [8.0512924, 7.9148078, 7.9524417, 7.9162955, 8.1651621, 0, 0, 0, 0, 0]\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew2UL66OEK8L"
   },
   "source": [
    "Where the following fields are:\n",
    "\n",
    "- **job_info**: Contains details about the job.\n",
    "  - **job_id**: Unique identifier for the job (`6679944a450099160ba0bf88`).\n",
    "  - **job_submission**: Information about the job submission.\n",
    "    - **job_tags**: Tags associated with the job (`port_opot_nasdaq100_d3`).\n",
    "    - **problem_config**: Configuration of the problem to be solved.\n",
    "      - **normalized_qudit_hamiltonian_optimization**: Specifies the problem type as normalized qudit Hamiltonian optimization.\n",
    "        - **hamiltonian_file_id**: ID of the file containing the Hamiltonian information (`6679944a98263204a365f329`).\n",
    "    - **device_config**: Configuration of the device used for the job.\n",
    "      - **dirac-3**: Specifies the device used (`dirac-3`).\n",
    "        - **num_samples**: Number of samples taken (value: 1).\n",
    "        - **relaxation_schedule**: Relaxation schedule parameter (value: 1).\n",
    "        - **sum_constraint**: Sum constraint parameter (value: 40).\n",
    "  - **job_status**: Status updates of the job.\n",
    "    - **submitted_at_rfc3339nano**: Time when the job was submitted (`2024-06-24T15:44:10.523Z`).\n",
    "    - **queued_at_rfc3339nano**: Time when the job was queued (`2024-06-24T15:44:10.524Z`).\n",
    "    - **running_at_rfc3339nano**: Time when the job started running (`2024-06-24T15:44:11.514Z`).\n",
    "    - **completed_at_rfc3339nano**: Time when the job completed (`2024-06-24T15:44:13.339Z`).\n",
    "  - **job_result**: Results of the job.\n",
    "    - **file_id**: ID of the file containing the job result (`6679944d98263204a365f32b`).\n",
    "    - **device_usage_s**: Time the device was used, in seconds (value: 2).\n",
    "\n",
    "- **status**: The current status of the job (`COMPLETED`).\n",
    "\n",
    "- **results**: The outcomes of the job.\n",
    "  - **counts**: Number of samples taken for each solution (value: [1]).\n",
    "  - **energies**: Energy values associated with the solutions (value: [-32319.5527344]).\n",
    "  - **solutions**: The actual solutions found, represented as a list of values (value: [[8.0512924, 7.9148078, 7.9524417, 7.9162955, 8.1651621, 0, 0, 0, 0, 0]]).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ws2ExQhEFRPZ"
   },
   "source": [
    "The solution weights are then adjusted to form a balanced portfolio and we obtain:\n",
    "\n",
    "```python\n",
    " Optimal_Portfolio_with_allocations = {\n",
    "    \"AAPL\": 0.2012823125160289,\n",
    "    \"NVDA\": 0.19787019747337747,\n",
    "    \"AMZN\": 0.19881104498513807,\n",
    "    \"MSFT\": 0.19790738997384238,\n",
    "    \"GOOG\": 0.20412905505161316\n",
    "  }\n",
    "\n",
    "Where The optimal allocations for the portfolio are as follows:\n",
    "  - **AAPL**: 20.13%\n",
    "  - **NVDA**: 19.79%\n",
    "  - **AMZN**: 19.88%\n",
    "  - **MSFT**: 19.79%\n",
    "  - **GOOG**: 20.41%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DieLNHWu7LK6"
   },
   "source": [
    "## Step 5\n",
    "Generate and Save Allocation Data:\n",
    "* Creates a DataFrame with stock allocations.\n",
    "* Saves the allocation data to a specified CSV file, appending if the file already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"qci_sol_%s.npy\" % current_date.strftime(\"%Y-%m-%d\"), sol)\n",
    "np.save(\"stock_list_%s.npy\" % current_date.strftime(\"%Y-%m-%d\"), stocks)    \n",
    "weight_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Stock\": [item for item in stock_allocations.keys()],\n",
    "        \"Allocation\": [\n",
    "            stock_allocations[item] for item in stock_allocations.keys()\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "weight_df[\"Date\"] = current_date\n",
    "weight_df = weight_df[weight_df[\"Allocation\"] > 0]\n",
    "weight_df[\"Stock_Count\"] = weight_df.shape[0]\n",
    "if os.path.exists(ALLOC_OUT_FILE):\n",
    "    weight_df.to_csv(\n",
    "        ALLOC_OUT_FILE,\n",
    "        index=False,\n",
    "        mode=\"a\",\n",
    "        header=False,\n",
    "    )\n",
    "else:\n",
    "    weight_df.to_csv(\n",
    "        ALLOC_OUT_FILE,\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display optimized portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(weight_df[[\"Stock\",\"Allocation\"]].tail(5).to_html()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCXfifwO-vGC"
   },
   "source": [
    "## Optimial Portfilio with Allocated weights:\n",
    "\n",
    "When we run our code, we will see that the optimal portfolio has the following stock allocations:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Stock</th>\n",
    "      <th>Allocation</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>NVDA</td>\n",
    "      <td>0.196433</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>AMZN</td>\n",
    "      <td>0.194561</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>MSFT</td>\n",
    "      <td>0.211609</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>AAPL</td>\n",
    "      <td>0.195888</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>GOOG</td>\n",
    "      <td>0.201509</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "5FCM4JR2Bocu",
    "outputId": "57e73846-4158-4a65-e9e2-5b526ff4177a"
   },
   "source": [
    "![weighted chart](figures/continuous/03.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T39FxGEb77Ol"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, we observe that Dirac effectively finds the solution and successfully solves the portfolio optimization problem. For a more challenging and comprehensive use case, refer to our example tutorial on optimizing a 100-asset portfolio over a 21-year period using the Nasdaq-100 as a benchmark with the Dirac-3 machine. Click [here](https://git.qci-dev.com/qci-dev/quantum-solutions/-/blob/main/qc/portfolio_optimization_dirac_3/build_unequal_nasdaq100_dirac3.py?ref_type=heads) to learn more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
