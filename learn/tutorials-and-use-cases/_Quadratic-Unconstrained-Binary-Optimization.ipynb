{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Unconstrained Binary Optimization (QUBO)\n",
    "## Introduction\n",
    "The Quadratic Unconstrained Binary Optimization (QUBO) is a foundational problem type used in many fields to formulate discrete combinatorial optimization problems. Generically, a Qubo is defined by linear and quadratic terms, but since $x^2 = x$ when $x \\in \\{0,1\\}$, we can simplify the optimization expression as such $f(x) = \\sum_{i} \\sum_{j} J_{ij} x_i x_j$, where $f: \\mathbb{B}^n \\rightarrow \\mathbb{R}$. Note that the coefficients naturally encodes as a square symmetric matrix, so that $f(x) = x^t Q x$, where $Q$ has entries $Q_{ij}$. The goal of the optimization problem is to find the binary vector, $x^{*}$, that minimizes $f(x)$, \n",
    "$x^{*} = \\min_{x} x^t Q x$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qci_client import QciClient\n",
    "client = QciClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading a QUBO job\n",
    "### Data format\n",
    "To upload a square symmetric matrix or Qubo, we encode it in a sparse matrix format as shown below. We use Numpy array notation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([[0, -1.5, 0.5], [-1.5, 0, 0], [0.5, 0, 0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubo_data = {\n",
    "  \"data\": Q,\n",
    "  \"file_name\": \"smallest_objective.json\", # can be any short string\n",
    "  \"num_variables\": 3, # number of rows\n",
    "  \"file_type\": \"qubo\" # defines the data type, 'qubo' in this case\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Uploading\n",
    "To upload the matrix encoded above in `qubo_data`, we use the the `qci_client` imported previously. The following line \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = qci.upload_file(qubo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response contains a file_id for the uploaded file. This id is provided when a job is run, along a few other parameters (see #Running). Note: the same `file_id` can be used multiple times to run a problem repeatedly. This enables an \"upload once, run many times\" scheme, which is especially useful for job types in which parameter searches may be involved.\n",
    "Triggering a job requires two items: first a job body that contains essential and optional metadata for the job, and second, the type of job a user wants to run. \n",
    "\n",
    "## Running a QUBO job\n",
    "### Job body\n",
    "This section defines the job body for a Qubo job.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_body = {\n",
    "\"job_name\": \"test-job\", # required, can be any string\n",
    "\"job_tags\": [\"foo\", \"bar\"], # optional, useful for tracking different jobs \n",
    "\"params\": params, # dictionary containing job parameters\n",
    "\"qubo_file_id\": response_json[\"file_id\"] # string id returned from file upload\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional parameters that can be included in the job using the params dictionary. Defaults are listed first, optional parameters in the complete list below. First, here is a params example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\"sampler_type\": \"csample\", \n",
    "\"n_samples\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Parameters list \n",
    "sampler_type: \"csample\", \"eqc1\", \"eqc2\"\n",
    "n_samples: defaults to 100 for csample jobs; defaults to 1 for eqc1 and eqc2 jobs. Note that each EQC sample is a job run in serial so multiple samples may incur a large overhead for large jobs. \n",
    "\n",
    "### Submitting a job\n",
    "To run a job, the API needs the job_body with the file_id from the upload step and the job \n",
    "result = qci.process_job(job_body=job_json, job_type=\"sample-qubo\")\n",
    "The process_job method is not asynchronous and includes a polling step within it. If the user wants more control the polling stage within process_job will serve as a good example of the few steps needed to create a sequence of asynchronous polling steps.\n",
    "The above call will return a result dictionary. To print the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = result[\"results\"]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Below we show how to query the result object if an error occurs:\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result['job_info']['details']['status'] == \"ERROR\":\n",
    "    print(result['job_info']['details']['status'])\n",
    "    print(result['job_info']['results']['error'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eqc-deploy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
