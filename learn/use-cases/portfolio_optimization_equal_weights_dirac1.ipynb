{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Equal Weighted Optimal portfolio\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This approach seeks to identify a sub-portfolio of stocks that have superior risk-return profiles compared to the full portfolio. This identifies opportunities for an investor to simplify their investment strategy without sacrificing (and potentially enhancing) the risk-adjusted return. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "Let K be the total number of available stocks to choose from (here $K = 253$), that is the size of the stock pool. We want to choose a subset of $K^\\prime$  ($K^\\prime < K$) stocks such that the portfolio risk is minimized, while the portfolio expected return is maximized, that is\n",
    "\n",
    "$\\min_{\\{x_{i}\\}_{i \\in \\{1, 2,..., K\\}}} [-E(R)^2 + \\xi VAR(R)]$\n",
    "\n",
    "where $R$ is the daily returns of the portfolio over some period of time, $VAR(R)$ and $E(R)$ are the variance and expectation of daily returns, $\\xi$ is a hyper-parameter, and $\\{x_{i}\\}$ are binary variables representing inclusion or exclusion of a stock. A large value means the focus of optimization is to increase return, whereas a small value indicates the reduction of risk is more important. As we can take both long and short positions on stocks, we assume that $x_1, x_2, ..., x_K$ corresponds to long positions on stocks 1 to $K$. \n",
    "\n",
    "As we are choosing a subset of K' stocks, we also need the following constraint,\n",
    "\n",
    "$\\sum_{i=1}^{2K} x_i = K^\\prime$\n",
    "\n",
    "Assuming that the same amount is invested on each of the K' selected stocks, the portfolio daily return at time t over a time period denoted by m can be expanded as follows,\n",
    "\n",
    "$R^{(m)}(t) =\\frac{1}{K^\\prime} \\sum_{i=1}^{K} x_i r^{(m)}_i(t)$\n",
    "\n",
    "where $r^{(m)}_i(t)$ is the daily return of stock i at time $t$ in time period $m$. The expectation of portfolio daily return over time period $m$ can thus be expanded as,\n",
    "\n",
    "$E(R^{(m)}) = \\frac{1}{K^\\prime} \\sum_{i=1}^{K} x_i E(r^{(m)}_i)$\n",
    "\n",
    "and the variance portfolio daily return over time period m is expanded as,\n",
    "\n",
    "$VAR(R^{(m)}) = \\frac{1}{K^{\\prime 2}} \\sum_{i=1}^{K} \\sum_{j=1}^{K} x_i x_j COV(r^{(m)}_i, r^{(m)}_j)$\n",
    "\n",
    "where $COV$ is the covariant function. \n",
    "\n",
    "The problem then reduces to\n",
    "\n",
    "$\\min_{\\{x_i\\}} {\\bf{x}^T} \\frac{1}{K^{\\prime 2}} [ Q^{(m)} - \\xi  P^{(m)}] {\\bf{x}}$\n",
    "\n",
    "where\n",
    "\n",
    "$Q^{(m)}_{ij} = COV(r^{(m)}_{i},  r^{(m)}_{j})$\n",
    "\n",
    "$P^{(m)}_{ij}= E(r_i^{(m)}) \\delta_{ij}$\n",
    "\n",
    "To avoid an over-fit on the portfolio data, we can minimize the average of the cost function over $M$ overlapping time periods, that is $m=1,2,...,M$. The problem becomes,\n",
    "\n",
    "$\\min_{\\{x_i\\}} {\\bf{x}^T} \\frac{1}{MK^{\\prime 2}} \\sum_{m=1}^{M}[ Q^{(m)} - \\xi  P^{(m)}] {\\bf{x}}$\n",
    "\n",
    "subject to,\n",
    "\n",
    "$\\sum_{i=1}^{K} x_i = K^\\prime$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "The above-mentioned approach was used to contruct an optimal portfolio based on the constitients of Nasdaq-100 index. The following constituents were used,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft Corp</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon.com Inc</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NVIDIA Corp</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tesla Inc</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Meta Platforms Inc</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PepsiCo Inc</td>\n",
       "      <td>PEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Broadcom Inc</td>\n",
       "      <td>AVGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Costco Wholesale Corp</td>\n",
       "      <td>COST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cisco Systems Inc</td>\n",
       "      <td>CSCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T-Mobile US Inc</td>\n",
       "      <td>TMUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adobe Inc</td>\n",
       "      <td>ADBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Texas Instruments Inc</td>\n",
       "      <td>TXN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Comcast Corp</td>\n",
       "      <td>CMCSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Honeywell International Inc</td>\n",
       "      <td>HON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Amgen Inc</td>\n",
       "      <td>AMGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Netflix Inc</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>QUALCOMM Inc</td>\n",
       "      <td>QCOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Starbucks Corp</td>\n",
       "      <td>SBUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Intel Corp</td>\n",
       "      <td>INTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Intuit Inc</td>\n",
       "      <td>INTU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gilead Sciences Inc</td>\n",
       "      <td>GILD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Advanced Micro Devices Inc</td>\n",
       "      <td>AMD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Automatic Data Processing Inc</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Intuitive Surgical Inc</td>\n",
       "      <td>ISRG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mondelez International Inc</td>\n",
       "      <td>MDLZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Applied Materials Inc</td>\n",
       "      <td>AMAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Analog Devices Inc</td>\n",
       "      <td>ADI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Regeneron Pharmaceuticals Inc</td>\n",
       "      <td>REGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PayPal Holdings Inc</td>\n",
       "      <td>PYPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Moderna Inc</td>\n",
       "      <td>MRNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Booking Holdings Inc</td>\n",
       "      <td>BKNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Vertex Pharmaceuticals Inc</td>\n",
       "      <td>VRTX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CSX Corp</td>\n",
       "      <td>CSX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Fiserv Inc</td>\n",
       "      <td>FISV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lam Research Corp</td>\n",
       "      <td>LRCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Activision Blizzard Inc</td>\n",
       "      <td>ATVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Micron Technology Inc</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>KLA Corp</td>\n",
       "      <td>KLAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Monster Beverage Corp</td>\n",
       "      <td>MNST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>O'Reilly Automotive Inc</td>\n",
       "      <td>ORLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Keurig Dr Pepper Inc</td>\n",
       "      <td>KDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ASML Holding NV</td>\n",
       "      <td>ASML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Synopsys Inc</td>\n",
       "      <td>SNPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Kraft Heinz Co/The</td>\n",
       "      <td>KHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Charter Communications Inc</td>\n",
       "      <td>CHTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>American Electric Power Co Inc</td>\n",
       "      <td>AEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Marriott International Inc/MD</td>\n",
       "      <td>MAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Palo Alto Networks Inc</td>\n",
       "      <td>PANW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Cintas Corp</td>\n",
       "      <td>CTAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Cadence Design Systems Inc</td>\n",
       "      <td>CDNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>MercadoLibre Inc</td>\n",
       "      <td>MELI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Dexcom Inc</td>\n",
       "      <td>DXCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Exelon Corp</td>\n",
       "      <td>EXC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Biogen Inc</td>\n",
       "      <td>BIIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>AstraZeneca PLC ADR</td>\n",
       "      <td>AZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NXP Semiconductors NV</td>\n",
       "      <td>NXPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Paychex Inc</td>\n",
       "      <td>PAYX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Enphase Energy Inc</td>\n",
       "      <td>ENPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Autodesk Inc</td>\n",
       "      <td>ADSK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Pinduoduo Inc ADR</td>\n",
       "      <td>PDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Ross Stores Inc</td>\n",
       "      <td>ROST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Fortinet Inc</td>\n",
       "      <td>FTNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Microchip Technology Inc</td>\n",
       "      <td>MCHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Xcel Energy Inc</td>\n",
       "      <td>XEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Lululemon Athletica Inc</td>\n",
       "      <td>LULU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Airbnb Inc</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Workday Inc</td>\n",
       "      <td>WDAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>PACCAR Inc</td>\n",
       "      <td>PCAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Walgreens Boots Alliance Inc</td>\n",
       "      <td>WBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>IDEXX Laboratories Inc</td>\n",
       "      <td>IDXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Electronic Arts Inc</td>\n",
       "      <td>EA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Marvell Technology Inc</td>\n",
       "      <td>MRVL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Old Dominion Freight Line Inc</td>\n",
       "      <td>ODFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>GLOBALFOUNDRIES Inc</td>\n",
       "      <td>GFS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>CoStar Group Inc</td>\n",
       "      <td>CSGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Dollar Tree Inc</td>\n",
       "      <td>DLTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Illumina Inc</td>\n",
       "      <td>ILMN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Baker Hughes Co</td>\n",
       "      <td>BKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Copart Inc</td>\n",
       "      <td>CPRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Constellation Energy Corp</td>\n",
       "      <td>CEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Cognizant Technology Solutions Corp</td>\n",
       "      <td>CTSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>JD.com Inc ADR</td>\n",
       "      <td>JD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Fastenal Co</td>\n",
       "      <td>FAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Verisk Analytics Inc</td>\n",
       "      <td>VRSK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Seagen Inc</td>\n",
       "      <td>SGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Crowdstrike Holdings Inc</td>\n",
       "      <td>CRWD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Diamondback Energy Inc</td>\n",
       "      <td>FANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Sirius XM Holdings Inc</td>\n",
       "      <td>SIRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>eBay Inc</td>\n",
       "      <td>EBAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Datadog Inc</td>\n",
       "      <td>DDOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Warner Bros Discovery Inc</td>\n",
       "      <td>WBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>ANSYS Inc</td>\n",
       "      <td>ANSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Atlassian Corp</td>\n",
       "      <td>TEAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rivian Automotive Inc</td>\n",
       "      <td>RIVN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Zoom Video Communications Inc</td>\n",
       "      <td>ZM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Zscaler Inc</td>\n",
       "      <td>ZS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Align Technology Inc</td>\n",
       "      <td>ALGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Lucid Group Inc</td>\n",
       "      <td>LCID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "df = pd.read_csv(\"nasdaq100_stocks.csv\")\n",
    "\n",
    "display(HTML(df[[\"Company\", \"Symbol\"]].to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the historical prices of the constituent stocks, as well as those of Nasdaq-100 (NDX) and equal weighted Nasdaq-100 (QQQE) using the Yahoo Finance Python library,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs                                                                                 \n",
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Define some parameters                                                                                            \n",
    "OUT_DIR = \"data\"\n",
    "\n",
    "# Get the list of all existing stocks                                                         \n",
    "stocks = list(df[\"Symbol\"].unique()) + [\"NDX\", \"QQQE\"] \n",
    "\n",
    "for stock in stocks:\n",
    "    try:\n",
    "        tmp_df = yf.Ticker(stock).history(\n",
    "            period=\"max\", interval=\"1d\",\n",
    "        )[[\"Close\"]].rename(\n",
    "            columns={\n",
    "                \"Close\": stock,\n",
    "            }\n",
    "        )\n",
    "        tmp_df[\"Date\"] = tmp_df.index\n",
    "        tmp_df.to_csv(\n",
    "            os.path.join(OUT_DIR, \"%s.csv\" % stock),\n",
    "            index=False,\n",
    "        )\n",
    "    except Exception as exc:\n",
    "        print(\"Could not get price for %s\" % stock)\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import some libraries and set some parameters,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs                                                                                \n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import warnings\n",
    "from functools import wraps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from qci_client import QciClient\n",
    "from qci_client import load_json_file\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ALPHA = 1.0 # The coeffient for penalty term (for linear constraint)\n",
    "N_SAMPLES = 20 # Number of solution samples\n",
    "XI = 5.0 # The xi variable as defined in Methodology\n",
    "K_PRIME = 30 # Number of selected stocks\n",
    "WINDOW_DAYS = 30 # Size of each sliding window in days\n",
    "WINDOW_OVERLAP_DAYS = 15 # Overlap between sliding windows in days\n",
    "IN_SAMPLE_DAYS = 180 # Size of the lookback period in days\n",
    "OUT_OF_SAMPLE_DAYS = 30 # Size of the horizon window in days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that calculate daily returns of all constituent stocks,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_returns(stocks, min_date, max_date):\n",
    "\n",
    "    min_date = pd.to_datetime(min_date)\n",
    "    max_date = pd.to_datetime(max_date)\n",
    "    return_df = None\n",
    "\n",
    "    for stock in stocks:\n",
    "        stock_df = pd.read_csv(\"data/%s.csv\" % stock)\n",
    "        stock_df[\"Date\"] = stock_df[\"Date\"].astype(\"datetime64[ns]\")\n",
    "        stock_df = stock_df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        stock_df[stock] = stock_df[stock].pct_change()\n",
    "        stock_df = stock_df.dropna()\n",
    "\n",
    "        stock_df = stock_df[\n",
    "            (stock_df[\"Date\"] >= min_date) & (stock_df[\"Date\"] <= max_date)\n",
    "        ]\n",
    "        \n",
    "        if return_df is None:\n",
    "            return_df = stock_df\n",
    "        else:\n",
    "            return_df = return_df.merge(stock_df, how=\"outer\", on=\"Date\",)\n",
    "\n",
    "    return_df = return_df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a function that calculate the hamiltonian matrix,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hamiltonian(\n",
    "    return_df, stocks, min_date, max_date,\n",
    "):\n",
    "\n",
    "    K = len(stocks)\n",
    "\n",
    "    # Calculate P and Q                                                                       \n",
    "    Q = np.zeros(shape=(K, K), dtype=\"d\")\n",
    "    P = np.zeros(shape=(K, K), dtype=\"d\")\n",
    "    m = 0\n",
    "    min_date = pd.to_datetime(min_date)\n",
    "    max_date = pd.to_datetime(max_date)\n",
    "    tmp_date = min_date\n",
    "    while tmp_date <= max_date:\n",
    "        tmp_min_date = tmp_date\n",
    "        tmp_max_date = tmp_date + datetime.timedelta(days=WINDOW_DAYS)\n",
    "        tmp_df = return_df[\n",
    "            (return_df[\"Date\"] >= tmp_min_date)\n",
    "            & (return_df[\"Date\"] <= tmp_max_date)\n",
    "        ]\n",
    "        r_list = []\n",
    "        for i in range(K):\n",
    "            r_list.append(np.array(tmp_df[stocks[i]]))\n",
    "\n",
    "        Q += np.cov(r_list)\n",
    "\n",
    "        for i in range(K):\n",
    "            for j in range(K):\n",
    "                P[i][j] += np.mean(r_list[i]) * np.mean(r_list[j])\n",
    "\n",
    "        tmp_date += datetime.timedelta(\n",
    "            days=WINDOW_DAYS - WINDOW_OVERLAP_DAYS,\n",
    "        )\n",
    "        m += 1\n",
    "\n",
    "    fct = m\n",
    "    if fct > 0:\n",
    "        fct = 1.0 / fct\n",
    "\n",
    "    P = fct * P\n",
    "    Q = fct * Q\n",
    "\n",
    "    # Calculate the Hamiltonian                                                              \n",
    "    H = -P + XI * Q\n",
    "\n",
    "    # make sure H is symmetric up to machine precision                                       \n",
    "    H = 0.5 * (H + H.transpose())\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we define a function that yields an optimal portfolio given a hamiltonian $H$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_portfolio(H, stocks, curr_date):\n",
    "\n",
    "    beg_time = time.time()\n",
    "\n",
    "    K = len(stocks)\n",
    "\n",
    "    assert H.shape[0] == K\n",
    "    assert H.shape[1] == K\n",
    "\n",
    "    # Generate the constraint                                                                \n",
    "    cons_lhs = np.zeros(shape=(K), dtype=np.float64)\n",
    "    for i in range(K):\n",
    "        cons_lhs[i] = 1.0\n",
    "\n",
    "    cons_lhs = np.array([cons_lhs])\n",
    "    cons_rhs = [K_PRIME]\n",
    "\n",
    "    # Create json objects                                                                     \n",
    "    objective_json = {}\n",
    "    objective_json[\"data\"] = []\n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            if H[i][j] == 0:\n",
    "                continue\n",
    "            objective_json[\"data\"].append(\n",
    "                {\"i\": i, \"j\": j, \"val\": H[i][j]}\n",
    "            )\n",
    "    objective_json[\"file_name\"] = \"objective_moody_equal_weights_eqc1.json\"\n",
    "    objective_json[\"num_variables\"] = K\n",
    "    objective_json[\"file_type\"] = \"objective\"\n",
    "\n",
    "    constraint_json = {}\n",
    "    constraint_json[\"data\"] = []\n",
    "    for i in range(cons_lhs.shape[0]):\n",
    "        for j in range(cons_lhs.shape[1]):\n",
    "            if cons_lhs[i][j] == 0:\n",
    "                continue\n",
    "            constraint_json[\"data\"].append(\n",
    "                {\"i\": i, \"j\": j, \"val\": cons_lhs[i][j]}\n",
    "            )\n",
    "    constraint_json[\"file_name\"] = \"constraints.json\"\n",
    "    constraint_json[\"num_constraints\"] = len(cons_rhs)\n",
    "    constraint_json[\"num_variables\"] = K\n",
    "    constraint_json[\"file_type\"] = \"constraints\"\n",
    "\n",
    "    rhs_json = {}\n",
    "    rhs_json[\"data\"] = cons_rhs\n",
    "    rhs_json[\"file_name\"] = \"rhs.json\"\n",
    "    rhs_json[\"num_constraints\"] = len(cons_rhs)\n",
    "    rhs_json[\"file_type\"] = \"rhs\"\n",
    "\n",
    "    job_json = {\n",
    "        \"job_name\": \"moodys_eqc1_equal_weights\",\n",
    "        \"job_tags\": [\"moody_nasda100_eqc1_equal_weights\",],\n",
    "        \"params\": {\n",
    "            \"sampler_type\": \"csample\", #\"eqc1\",                                               \n",
    "            \"n_samples\": N_SAMPLES,\n",
    "            \"alpha\": ALPHA,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Solve the optimization problem                                                          \n",
    "    qci = QciClient()\n",
    "\n",
    "    response_json = qci.upload_file(objective_json)\n",
    "    objective_file_id = response_json[\"file_id\"]\n",
    "\n",
    "    response_json = qci.upload_file(constraint_json)\n",
    "    constraint_file_id = response_json[\"file_id\"]\n",
    "\n",
    "    response_json = qci.upload_file(rhs_json)\n",
    "    rhs_file_id = response_json[\"file_id\"]\n",
    "\n",
    "    job_json[\"constraints_file_id\"] = constraint_file_id\n",
    "    job_json[\"objective_file_id\"] = objective_file_id\n",
    "    job_json[\"rhs_file_id\"] = rhs_file_id\n",
    "\n",
    "    job_response_json = qci.process_job(\n",
    "        job_body=job_json, job_type=\"sample-constraint\",\n",
    "    )\n",
    "\n",
    "    print(job_response_json)\n",
    "\n",
    "    if job_response_json[\"job_info\"][\"details\"][\"status\"] == \"COMPLETED\":\n",
    "        results = job_response_json[\"results\"]\n",
    "        energies = results[\"energies\"]\n",
    "        samples = results[\"samples\"]\n",
    "        is_feasibles = results[\"is_feasible\"]\n",
    "    else:\n",
    "        assert False, job_response_json[\"job_info\"][\"results\"][\"error\"]\n",
    "\n",
    "    # The sample solutions are sorted by energy                                               \n",
    "    sol = None\n",
    "    for i, item in enumerate(samples):\n",
    "        sol = item\n",
    "        is_feasible = is_feasibles[i]\n",
    "\n",
    "        if is_feasible:\n",
    "            break\n",
    "\n",
    "    if not is_feasible:\n",
    "        print(\"Solution is not feasible!\")\n",
    "\n",
    "    assert len(sol) == K, \"Inconsistent solution size!\"\n",
    "\n",
    "    if sum(sol) != K_PRIME:\n",
    "        print(\n",
    "            \"Expected to select %d stocks, but selected %d!\"\n",
    "            % (K_PRIME, sum(sol))\n",
    "\t)\n",
    "\n",
    "    sel_stocks = []\n",
    "    for i in range(K):\n",
    "        if sol[i] > 0:\n",
    "            sel_stocks.append(stocks[i])\n",
    "\n",
    "    print(\n",
    "        \"In optimize_portfolio; done with checking constraints; %0.2f seconds!\"\n",
    "        % (time.time() - beg_time)\n",
    "    )\n",
    "\n",
    "    return sol, sel_stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We can now test the approach over a period of time, between 2020-01-15 to 2023-12-30. We define,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(curr_date):\n",
    "\n",
    "    print(\"Processing curr date:\", curr_date)\n",
    "\n",
    "    curr_date = pd.to_datetime(curr_date)\n",
    "    min_ins_date = curr_date - datetime.timedelta(days=IN_SAMPLE_DAYS)\n",
    "    max_ins_date = curr_date - datetime.timedelta(days=1)\n",
    "    min_oos_date = curr_date\n",
    "    max_oos_date = curr_date + datetime.timedelta(days=OUT_OF_SAMPLE_DAYS)\n",
    "\n",
    "    df = pd.read_csv(\"nasdaq100_stocks.csv\", low_memory=False)\n",
    "\n",
    "    stocks = list(set(df[\"Symbol\"]))\n",
    "\n",
    "    ins_return_df = get_stock_returns(stocks, min_ins_date, max_ins_date)\n",
    "    oos_return_df = get_stock_returns(stocks, min_oos_date, max_oos_date)\n",
    "\n",
    "    ins_return_df = ins_return_df.sort_values(\"Date\")\n",
    "    ins_return_df = ins_return_df.fillna(method=\"ffill\").fillna(0)\n",
    "\n",
    "    oos_return_df = oos_return_df.sort_values(\"Date\")\n",
    "    oos_return_df = oos_return_df.fillna(method=\"ffill\").fillna(0)\n",
    "\n",
    "    H = get_hamiltonian(ins_return_df, stocks, min_ins_date, max_ins_date)\n",
    "\n",
    "    sol, sel_stocks = optimize_portfolio(H, stocks, curr_date)\n",
    "\n",
    "    sel_stock_df = pd.DataFrame()\n",
    "    sel_stock_df[\"Date\"] = [curr_date] * len(sel_stocks)\n",
    "    sel_stock_df[\"Stock\"] = sel_stocks\n",
    "\n",
    "    return sel_stock_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run a backtest,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = pd.to_datetime(\"2022-02-14\") #\"2020-01-01\")                                    \n",
    "max_date = pd.to_datetime(\"2023-12-30\")\n",
    "\n",
    "SEL_STOCK_OUT_FILE = \"selected_stocks.csv\"\n",
    "\n",
    "curr_date = min_date\n",
    "while curr_date < max_date:\n",
    "    tmp_sel_stock_df = run(curr_date)\n",
    "\n",
    "    if os.path.exists(SEL_STOCK_OUT_FILE):\n",
    "        tmp_sel_stock_df.to_csv(\n",
    "            SEL_STOCK_OUT_FILE, index=False, mode=\"a\", header=False,\n",
    "        )\n",
    "    else:\n",
    "        tmp_sel_stock_df.to_csv(\n",
    "            SEL_STOCK_OUT_FILE, index=False,\n",
    "        )\n",
    "\n",
    "    curr_date += datetime.timedelta(days=OUT_OF_SAMPLE_DAYS + 1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the optimal portfolio values over the period of time it was tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs                                                                                 \n",
    "import sys\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set params                                                                                  \n",
    "INIT_PORT_VAL = 1000000.0\n",
    "OUT_OF_SAMPLE_DAYS = 30\n",
    "K_PRIME = 30\n",
    "XI = 5.0\n",
    "IND_SYMBOL_1 = \"QQQE\"\n",
    "IND_SYMBOL_2 = \"NDX\"\n",
    "\n",
    "SEL_STOCK_FILE = \"selected_stocks.csv\"\n",
    "INDEX_FILE_1 = \"data/%s.csv\" % IND_SYMBOL_1\n",
    "INDEX_FILE_2 = \"data/%s.csv\" % IND_SYMBOL_2\n",
    "\n",
    "# Read allocation file                                                                        \n",
    "df = pd.read_csv(SEL_STOCK_FILE)\n",
    "df[\"Date\"] = df[\"Date\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "# Loop through dates and calculate port value                                                 \n",
    "beg_port_val = INIT_PORT_VAL\n",
    "df = df.sort_values(\"Date\")\n",
    "adj_dates = sorted(df[\"Date\"].unique())\n",
    "num_adj_dates = len(adj_dates)\n",
    "dates = None\n",
    "port_vals = None\n",
    "for i in range(num_adj_dates):\n",
    "\n",
    "    print(\n",
    "        \"Processing adjustment date %s\"\n",
    "        % pd.to_datetime(adj_dates[i]).strftime(\"%Y-%m-%d\")\n",
    "    )\n",
    "\n",
    "    beg_date = pd.to_datetime(adj_dates[i])\n",
    "    if i < num_adj_dates - 1:\n",
    "        end_date = pd.to_datetime(adj_dates[i + 1])\n",
    "    else:\n",
    "        end_date = beg_date + datetime.timedelta(days=OUT_OF_SAMPLE_DAYS)\n",
    "\n",
    "    tmp_df = df[df[\"Date\"] == beg_date]\n",
    "    stocks = tmp_df[\"Stock\"]\n",
    "    stocks = list(set(stocks))\n",
    "\n",
    "    if end_date > pd.to_datetime(\"2023-10-20\"):\n",
    "        stocks = list(set(stocks) - {\"ATVI\"})\n",
    "\n",
    "    all_dates = [beg_date]\n",
    "    date0 = beg_date\n",
    "    while date0 < end_date:\n",
    "        date0 = date0 + datetime.timedelta(days=1)\n",
    "        all_dates.append(date0)\n",
    "\n",
    "    price_df = pd.DataFrame({\"Date\": all_dates})\n",
    "\n",
    "    for stock in stocks:\n",
    "        stock_df = pd.read_csv(\"data/%s.csv\" % stock)\n",
    "        stock_df[\"Date\"] = stock_df[\"Date\"].astype(\"datetime64[ns]\")\n",
    "        stock_df = stock_df[\n",
    "            (stock_df[\"Date\"] >= beg_date) & (stock_df[\"Date\"] <= end_date)\n",
    "        ]\n",
    "\n",
    "        if price_df is None:\n",
    "            price_df = stock_df\n",
    "        else:\n",
    "            price_df = price_df.merge(stock_df, on=\"Date\", how=\"outer\")\n",
    "\n",
    "    price_df = price_df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    price_df = price_df.sort_values(\"Date\")\n",
    "\n",
    "    tmp_dates = np.array(price_df[\"Date\"])\n",
    "    tmp_port_vals = np.zeros(shape=(price_df.shape[0]))\n",
    "\n",
    "    assert price_df.shape[0] > 0\n",
    "\n",
    "    for stock in stocks:\n",
    "        prices = np.array(price_df[stock])\n",
    "        beg_price = prices[0]\n",
    "        stock_wt = 1.0 / len(stocks)\n",
    "\n",
    "        assert beg_price > 0, \"Error in data for %s\" % stock\n",
    "\n",
    "        stock_count = stock_wt * beg_port_val / beg_price\n",
    "        tmp_port_vals += stock_count * prices\n",
    "\n",
    "    if dates is None:\n",
    "        dates = tmp_dates\n",
    "    else:\n",
    "        dates = np.concatenate([dates, tmp_dates])\n",
    "\n",
    "    if port_vals is None:\n",
    "        port_vals = tmp_port_vals\n",
    "    else:\n",
    "        port_vals = np.concatenate([port_vals, tmp_port_vals])\n",
    "\n",
    "    beg_port_val = port_vals[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the optimal portfolio values and compare them with those of Nasdaq-100 and equal-weighted Nasdaq-100 indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot    \n",
    "out_df = pd.DataFrame({\"Date\": dates, \"Port_Val\": port_vals})\n",
    "out_df[\"Date\"] = out_df[\"Date\"].astype(\"datetime64[ns]\")\n",
    "ind_df_1 = pd.read_csv(INDEX_FILE_1)\n",
    "ind_df_1[\"Date\"] = ind_df_1[\"Date\"].astype(\"datetime64[ns]\")\n",
    "min_date = out_df[\"Date\"].min()\n",
    "max_date = out_df[\"Date\"].max()\n",
    "ind_df_1 = ind_df_1[\n",
    "    (ind_df_1[\"Date\"] >= min_date) & (ind_df_1[\"Date\"] <= max_date)\n",
    "]\n",
    "ind_vals_1 = np.array(ind_df_1[IND_SYMBOL_1])\n",
    "fct = INIT_PORT_VAL / ind_vals_1[0]\n",
    "ind_vals_1 *= fct\n",
    "\n",
    "ind_df_2 = pd.read_csv(INDEX_FILE_2)\n",
    "ind_df_2[\"Date\"] = ind_df_2[\"Date\"].astype(\"datetime64[ns]\")\n",
    "min_date = out_df[\"Date\"].min()\n",
    "max_date = out_df[\"Date\"].max()\n",
    "ind_df_2 = ind_df_2[\n",
    "    (ind_df_2[\"Date\"] >= min_date) & (ind_df_2[\"Date\"] <= max_date)\n",
    "]\n",
    "ind_vals_2 = np.array(ind_df_2[IND_SYMBOL_2])\n",
    "fct = INIT_PORT_VAL / ind_vals_2[0]\n",
    "ind_vals_2 *= fct\n",
    "\n",
    "plt.plot(\n",
    "    out_df[\"Date\"], out_df[\"Port_Val\"],                                            \n",
    "    ind_df_1[\"Date\"], ind_vals_1,\n",
    "    ind_df_2[\"Date\"], ind_vals_2,\n",
    ")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "\n",
    "plt.legend(\n",
    "    [\n",
    "        \"Equal weighted optimal portfolio\",                  \n",
    "        \"Equal weighted Nasdaq 100\",\n",
    "        \"Nasdaq 100\",\n",
    "    ]\n",
    ")                                 \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sample results tha compares the optimal portfolio value to Nadaq-100 and equal-weighted Nasdaq-100 indexes.\n",
    "\n",
    "<img src=\"equal_wt_port_perf_30_xi5.png\" alt=\"fishy\" class=\"bg-primary mb-1\" width=\"900px\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
