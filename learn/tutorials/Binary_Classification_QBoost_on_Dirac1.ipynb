{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QBoost: A QUBO Based Binary Classification Method\n",
    "\n",
    "\n",
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Methodology\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation QBoost Algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from functools import wraps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "from qci_client import QciClient\n",
    "from qci_client import load_json_file\n",
    "\n",
    "PLOT_FLAG = False\n",
    "\n",
    "\n",
    "def timer(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        beg_time = time.time()\n",
    "        val = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        tot_time = end_time - beg_time\n",
    "\n",
    "        print(\"Runtime of %s: %0.2f seconds!\" % (func.__name__, tot_time,))\n",
    "\n",
    "        return val\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "class WeakClassifierDct:\n",
    "    def __init__(self, fea_ind_list, X_train, y_train):\n",
    "\n",
    "        assert X_train.shape[0] == len(y_train)\n",
    "\n",
    "        self.fea_ind_list = fea_ind_list\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        X_tmp = self.X_train.transpose()[self.fea_ind_list].transpose()\n",
    "\n",
    "        self.clf.fit(X_tmp, self.y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        X_tmp = X.transpose()[self.fea_ind_list].transpose()\n",
    "\n",
    "        return self.clf.predict(X_tmp)\n",
    "\n",
    "\n",
    "class QBoost:\n",
    "    def __init__(\n",
    "        self,\n",
    "        lambda_coef,\n",
    "        num_eqc_samples=10,\n",
    "        alpha=1.0,\n",
    "        theta=0.0,\n",
    "        mode=\"dct\",\n",
    "    ):\n",
    "\n",
    "        self.lambda_coef = lambda_coef\n",
    "        self.num_eqc_samples = num_eqc_samples\n",
    "        self.alpha = alpha\n",
    "        self.theta = theta\n",
    "        self.mode = mode\n",
    "        self.weights = None\n",
    "        self.h_list = None\n",
    "\n",
    "\n",
    "    @timer\n",
    "    def _build_weak_classifiers_dct(self, X, y):\n",
    "\n",
    "        S = X.shape[0]\n",
    "        M = X.shape[1]\n",
    "\n",
    "        assert len(y) == S\n",
    "\n",
    "        h_list = []\n",
    "\n",
    "        for l in range(M):\n",
    "            weak_classifier = WeakClassifierDct([l], X, y)\n",
    "            weak_classifier.train()\n",
    "\n",
    "            h_list.append(weak_classifier)\n",
    "\n",
    "        for i in range(M):\n",
    "            for j in range(i + 1, M):\n",
    "                weak_classifier = WeakClassifierDct([i, j], X, y)\n",
    "                weak_classifier.train()\n",
    "                h_list.append(weak_classifier)\n",
    "\n",
    "        for i in range(M):\n",
    "            for j in range(i + 1, M):\n",
    "                for k in range(j + 1, M):                \n",
    "                    weak_classifier = WeakClassifierDct([i, j, k], X, y)\n",
    "                    weak_classifier.train()\n",
    "                    h_list.append(weak_classifier)\n",
    "                \n",
    "        return h_list\n",
    "    \n",
    "    \n",
    "    @timer\n",
    "    def _get_hamiltonian(self, X, y):\n",
    "\n",
    "        S = X.shape[0]\n",
    "        M = X.shape[1]\n",
    "\n",
    "        if if self.mode == \"dct\":\n",
    "            h_list = self._build_weak_classifiers_dct(X, y)          \n",
    "        else:\n",
    "            assert False, \"Incorrect mode <%s>!\" % self.mode\n",
    "\n",
    "        self.h_list = h_list\n",
    "\n",
    "        N = len(h_list)\n",
    "\n",
    "        Q = np.zeros(shape=(N, N), dtype=\"d\")\n",
    "        P = np.zeros(shape=(N, N), dtype=\"d\")\n",
    "\n",
    "        h_vals = np.array([h_list[i].predict(X) for i in range(N)])\n",
    "\n",
    "        assert h_vals.shape[0] == N\n",
    "        assert h_vals.shape[1] == S\n",
    "\n",
    "        for i in range(N):\n",
    "            P[i][i] = self.lambda_coef - (2.0 / N) * np.sum(h_vals[i] * y)\n",
    "            for j in range(N):\n",
    "                Q[i][j] = (1.0 / N ** 2) * np.sum(h_vals[i] * h_vals[j])\n",
    "\n",
    "        # Calculate the Hamiltonian\n",
    "        H = Q + P\n",
    "\n",
    "        # make sure H is symmetric up to machine precision\n",
    "        H = 0.5 * (H + H.transpose())\n",
    "\n",
    "        print(\"The size of the hamiltonian is %d by %d\" % (N, N))\n",
    "        \n",
    "        return H\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.weights = weights\n",
    "\n",
    "    @timer\n",
    "    def train(self, X, y):\n",
    "\n",
    "        H = self._get_hamiltonian(X, y)\n",
    "\n",
    "        N = H.shape[0]\n",
    "\n",
    "        objective_json = {}\n",
    "        objective_json[\"data\"] = []\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if H[i][j] == 0:\n",
    "                    continue\n",
    "                objective_json[\"data\"].append(\n",
    "                    {\"i\": i, \"j\": j, \"val\": H[i][j]}\n",
    "                )\n",
    "        objective_json[\"file_name\"] = \"qboost.json\"\n",
    "        objective_json[\"num_variables\"] = N\n",
    "        objective_json[\"file_type\"] = \"qubo\"\n",
    "\n",
    "        json.dump(objective_json, open(\"objective.json\", \"w\"))\n",
    "        \n",
    "        job_json = {\n",
    "            \"job_name\": \"qboost_classifier\",\n",
    "            \"job_tags\": [\"qboost\"],\n",
    "            \"params\": {\n",
    "                \"sampler_type\": \"csample\", # \"eqc1\"\n",
    "                \"n_samples\": self.num_eqc_samples,\n",
    "                \"alpha\": self.alpha,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # Solve the optimization problem\n",
    "        qci = QciClient()\n",
    "\n",
    "        response_json = qci.upload_file(objective_json)\n",
    "        objective_file_id = response_json[\"file_id\"]\n",
    "        job_json[\"qubo_file_id\"] = objective_file_id\n",
    "\n",
    "        job_response_json = qci.process_job(\n",
    "            job_body=job_json, job_type=\"sample-qubo\",\n",
    "        )\n",
    "\n",
    "        #print(job_response_json)\n",
    "\n",
    "        if (\n",
    "            job_response_json[\"job_info\"][\"details\"][\"status\"]\n",
    "            == \"COMPLETED\"\n",
    "        ):\n",
    "            results = job_response_json[\"results\"]\n",
    "            energies = results[\"energies\"]\n",
    "            samples = results[\"samples\"]\n",
    "        else:\n",
    "            assert False, job_response_json[\"job_info\"][\"results\"][\"error\"]\n",
    "\n",
    "        if True:\n",
    "            print(\"Energies:\", energies)\n",
    "\n",
    "        # Pick a feasible solution with lowest energy\n",
    "        # The sample solutions are sorted by energy\n",
    "        sol = samples[0]\n",
    "\n",
    "        assert len(sol) == N, \"Inconsistent solution size!\"\n",
    "\n",
    "        self.weights = np.array(sol)\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        assert self.weights is not None, \"Model is not trained!\"\n",
    "        assert self.h_list is not None, \"Model is not trained!\"\n",
    "\n",
    "        assert len(self.weights) == len(self.h_list), \"Inconsisent sizes!\"\n",
    "\n",
    "        N = len(self.weights)\n",
    "        tmp_vals = np.zeros(shape=(X.shape[0]), dtype=\"d\")\n",
    "\n",
    "        fct = sum(self.weights)\n",
    "        if fct > 0:\n",
    "            fct = 1.0 / fct\n",
    "\n",
    "        for i in range(N):\n",
    "            # if self.weights[i] > 0:\n",
    "            #     print(self.weights[i], set(self.h_list[i].predict(X)))\n",
    "            tmp_vals += self.weights[i] * self.h_list[i].predict(X)\n",
    "\n",
    "        tmp_vals = fct * tmp_vals\n",
    "\n",
    "        pred_vals = np.sign(tmp_vals - self.theta)\n",
    "\n",
    "        for i in range(len(pred_vals)):\n",
    "            if pred_vals[i] == 0:\n",
    "                pred_vals[i] = -1.0\n",
    "\n",
    "        return pred_vals\n",
    "\n",
    "    def save_weights(self, file_name):\n",
    "        np.save(file_name, self.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now print the feature names and get the total count of features in the dataset,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Some parameters\n",
    "TEST_SIZE = 0.2\n",
    "LAMBDA_COEF = 0.5\n",
    "\n",
    "# Read dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 0:\n",
    "        y[i] = -1\n",
    "    elif y[i] == 2:\n",
    "        y[i] = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=42,\n",
    ")\n",
    "print(Counter(y_train))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(Counter(y_test))\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "obj = QBoost(lambda_coef=LAMBDA_COEF, num_eqc_samples=10, alpha=1.0, mode=\"dct\")\n",
    "\n",
    "obj.train(X_train, y_train)\n",
    "\n",
    "y_train_prd = obj.predict(X_train)\n",
    "y_test_prd = obj.predict(X_test)\n",
    "\n",
    "print(Counter(y_train_prd))\n",
    "print(Counter(y_test_prd))\n",
    "\n",
    "print(\"Weights:\", obj.weights)\n",
    "\n",
    "print(\n",
    "    \"Train precision:\",\n",
    "    precision_score(y_train, y_train_prd, labels=[-1, 1], pos_label=1),\n",
    ")\n",
    "print(\n",
    "    \"Train recall:\",\n",
    "    recall_score(y_train, y_train_prd, labels=[-1, 1], pos_label=1),\n",
    ")\n",
    "print(\n",
    "    \"Train accuracy:\",\n",
    "    accuracy_score(y_train, y_train_prd),\n",
    ")\n",
    "print(\n",
    "    \"Train confusion matrix:\",\n",
    "    confusion_matrix(y_train, y_train_prd, labels=[-1, 1]),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Test precision:\",\n",
    "    precision_score(y_test, y_test_prd, labels=[-1, 1], pos_label=1),\n",
    ")\n",
    "print(\n",
    "    \"Test recall:\",\n",
    "    recall_score(y_test, y_test_prd, labels=[-1, 1], pos_label=1),\n",
    ")\n",
    "print(\n",
    "    \"Test accuracy:\",\n",
    "    accuracy_score(y_test, y_test_prd),\n",
    ")\n",
    "print(\n",
    "    \"Test confusion matrix:\",\n",
    "    confusion_matrix(y_test, y_test_prd, labels=[-1, 1]),\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
